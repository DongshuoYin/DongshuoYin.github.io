<!DOCTYPE html>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0">
  <meta name="author" content="DongshuoYin">
  <title>Dongshuo Yin's Homepage</title>

  <!-- CSS  -->
  <link href="./materialize.min.css" type="text/css" rel="stylesheet" media="screen,projection">
  <link href="./aos.css" type="text/css" rel="stylesheet" media="screen,projection">
  <link href="./style.css" type="text/css" rel="stylesheet" media="screen,projection">
  <link rel="shortcut icon" href="./thu-short.png">
<script type="text/javascript" src="./jquery-1.12.4.min.js.下载"></script><style>@-moz-keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}@-webkit-keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}@-o-keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}@keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}embed,object{animation-duration:.001s;-ms-animation-duration:.001s;-moz-animation-duration:.001s;-webkit-animation-duration:.001s;-o-animation-duration:.001s;animation-name:nodeInserted;-ms-animation-name:nodeInserted;-moz-animation-name:nodeInserted;-webkit-animation-name:nodeInserted;-o-animation-name:nodeInserted;}</style></head>
<body data-aos-easing="ease" data-aos-duration="400" data-aos-delay="0">
  
  <div class="navbar-fixed">

    <nav class="white">
      <div class="nav-wrapper container"><a id="logo-container" href="https://dongshuoyin.github.io/#" class="brand-logo"></a>
        <ul class="left">
          <li><a class="nav-item waves-effect waves-light active" href="https://dongshuoyin.github.io/#home">Home</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://dongshuoyin.github.io/#biography">Biography</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://dongshuoyin.github.io/#news">News</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://dongshuoyin.github.io/#publications">Publications</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://dongshuoyin.github.io/#WorkExperience">Work Experience</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://dongshuoyin.github.io/#education">Education</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://dongshuoyin.github.io/#awards">Awards</a></li>
        </ul>
        </ul>
      </div>
    </nav>
  </div>
  

<!--==========================================
                   Profile
===========================================-->

<div id="home" class="parallax-container scrollspy">


  <div class="container row cover-block">

    <div class="profile-image-block col s12 m12 l4 center">
        <img class="responsive-img profile-photo z-depth-2" src="./yds.jpg" width="319">
    </div>

    <div class="profile-content-block col s12 m12 l8">
        <h5 class="profile-name"><font color="#000000">Dongshuo Yin (殷东硕)</h5>
        <hr>
        <h6 class="profile-link"><b>Postdoc researcher in Tsinghua University</b></h6>
        <h6 class="profile-link"><b>Ph.D. at University of Chinese Academy of Sciences/Aerospace Information Research Institute, Chinese Academy of Sciences</b></h6>
        <h6 class="profile-link"><b>Email: yindongshuo19@mails.ucas.ac.cn or yinds@mail.tsinghua.edu.cn</b></h6>
      
    </div>    
  
  </div>
  
<!--  <div class="parallax"><img src="./bg-yds3.jpg" alt="Unsplashed background img 1" style="display: block; transform: translate3d(-50%, 153px, 0px);"></div>-->

</div>
  
 

<!--==========================================
                   About
===========================================-->
<div id="biography">

  <div class="row container">
    <br><br>
    <div class="row">
      <div class="title"> Biography [<a href="https://scholar.google.com.hk/citations?user=Db7-HnkAAAAJ&hl=zh-CN&oi=ao"><b>Google Scholar</b></a>] </a>
</div>
    <hr>
    </div>
    
    <div class="row">
      <p>
         Dongshuo Yin is currently a postdoc researcher in <a href="https://www.tsinghua.edu.cn/">Tsinghua University</a>, working with <a href="https://www.tsinghua.edu.cn/info/1167/108283.htm">Prof. Shimin Hu</a> at <a href="https://www.cs.tsinghua.edu.cn/">the Department of Computer Science and Technology</a>. Before that, Dongshuo Yin received the PhD degree from <a href="https://eece.ucas.ac.cn/">School of Electronic, Electrical and Communication Engineering</a>, <a href="https://www.ucas.ac.cn/">University of Chinese Academy of Sciences</a> & <a href="http://www.aircas.ac.cn/">Institute of Electronics (Aerospace Information Research Institute), Chinese Academy of Sciences</a>, advised by <a href="http://people.ucas.ac.cn/~sunxian">Prof. Xian Sun</a>.    In 2024, he was selected for Tsinghua University's Shuimu Tsinghua Scholar program and received the CAS President's Award. From 2023 to 2024, he conducted collaborative research at Microsoft Research Asia (MSRA) and Alibaba Group. As the first author, he has published multiple papers in top-tier international journals/conferences, including Nature Communications, IEEE CVPR, IEEE ICCV, ACM MM, and IEEE TITS. He also serves as a reviewer for prestigious international publications such as NeurIPS, CVPR, ICCV, ICLR, IEEE TIP, and IEEE TMM. His research focuses on ​​computer vision​​, ​​parameter-efficient fine-tuning​​, ​​video generation​​, ​​AIGC​​, and ​​remote sensing image interpretation​​. His work in Nature Communications (global garbage dump detection and analysis) has been featured by Voice of CAS, Tencent News, NetEase News, and Sohu News, with the paper surpassing ​​20,000 reads​​.    
</a>
      </p>
<!--      <p>-->
<!--        Dongshuo Yin received the B. E. degree from XXXXX, China, in 2019.-->
<!--      </p>-->
      <p>
          殷东硕，清华大学计算机系博士后/助理研究员，合作导师胡事民院士。2024年毕业于中国科学院空天信息创新研究院/中国科学院大学并获工学博士学位，导师为孙显研究员（国家杰青）。2025年入选人社部博士后创新人才支持计划（博新计划，全国计算机科学与技术学科20人，总资助率约1%）。2024年入选清华大学“水木学者”计划，同年获得“中国科学院院长奖”。2023年至2024年在微软亚洲研究院（Microsoft Research Asia, MSRA）和阿里巴巴集团（Alibaba Group）进行科研合作交流。以一作身份在Nature子刊Nature Communications、IEEE CVPR、IEEE ICCV、ACM MM、IEEE TITS等国际顶级期刊/会议发表论文多篇，并担任NeurIPS、CVPR、ICCV、ICLR、IEEE TIP、IEEE TMM等多个国际出版物的审稿人。研究方向包括计算机视觉、参数高效微调、视频生成、AIGC以及遥感图像解译等领域。Nature子刊工作（全球垃圾堆检测与分析）被“中科院之声”、“腾讯新闻”、“网易新闻”、“搜狐新闻”报导，相关论文发表一年内已被阅读过万次。
      </p>


        <p>
        如果对相关工作感兴趣，欢迎邮件联系我。同时，非常欢迎对科学研究感兴趣的本科生或研究生联系我进行线下（清华大学及五道口附近）或线上的合作交流。
        </p>

  </div>
</div>



<!--==========================================
                   News
===========================================-->
<div id="news">

  <div class="row container">
    <div class="row">
      <div class="title">🔥 News</div>
      <hr>
    </div>
    <div class="row">
      <ul>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 2025: &nbsp; Awarded with <a href="https://www.chinapostdoctor.org.cn/prod-api/profile/info/fujian/20250603/4729c852-17fa-4f33-9303-be827a0920e8.pdf"><b>China National Postdoctoral Program for Innovative Talents (2025年度人社部博士后创新人才支持计划, 博新计划) !</b></a>
        </li>
             
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 2025: &nbsp;  ​​One paper about <b>video editing (AIGC)</b> has been submitted to ​<a href="https://arxiv.org/pdf/2505.07057"><b>arXiv</b></a>, with me as the <b>corresponding author</b>.
        </li>
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 2025: &nbsp; Mona (CVPR 2025) has been reported by <a href="https://mp.weixin.qq.com/s/qL8IzpaFUWKBxUsodshH0w"><b>Extreme Mart</b></a>, <a href="https://mp.weixin.qq.com/s/OM0hZMX_KcEXvt0DorPhOw"><b>PaperWeekly</b></a>, <a href="https://mp.weixin.qq.com/s/NsNRmzn_haq_ly63W0WjAQ"><b>QbitAI (量子位)</b></a>, and <a href="https://mp.weixin.qq.com/s/15bO4RD8Iu0TcEfvHGYF0A"><b>Synces (机器之心)</b></a> !
        </li>
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 2025: &nbsp; Our project <a href="https://github.com/Leiyi-Hu/mona"><b>Mona (CVPR 2025)</b></a> has earned 300+ GitHub Stars⭐ !
        </li>


        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 2025: &nbsp; One paper is accepted by <a href="https://openaccess.thecvf.com/content/CVPR2025/papers/Yin_5100_Breaking_Performance_Shackles_of_Full_Fine-Tuning_on_Visual_Recognition_CVPR_2025_paper.pdf"><b>CVPR 2025 Main Track</b></a> !
        </li>
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 2024: &nbsp; One paper is accepted by <a href="https://ieeexplore.ieee.org/document/10740309"><b>IEEE Transactions on Geoscience and Remote Sensing (TGRS)</b></a>.
        </li>


        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 2024: &nbsp; One paper is accepted by <a href="https://dl.acm.org/doi/10.1145/3664647.3680940"><b>ACM MM 2024 Main Track</b></a> !
        </li>
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 2024: &nbsp; Awarded with <font color="#0000dd"><b>Shuimu Tsinghua Scholar! (清华大学水木学者)</b></font> 
        </li>
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 2024: &nbsp; Awarded with <font color="#0000dd"><b>CAS President Scholarship! (中国科学院院长奖，<1%)</b></font> 
        </li>
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 2024: &nbsp; One paper is accepted by <a href="https://ieeexplore.ieee.org/document/10385180"><b>IEEE Transactions on Geoscience and Remote Sensing (TGRS)</b></a>.
        </li>
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 2023: &nbsp; Our paper on Nature Communications has been read <a href="https://www.nature.com/articles/s41467-023-37136-1"><b>20,000+</b></a> times and has been reported by <a href="https://new.qq.com/rain/a/20230617A0131300.html"><b>Tencent News</b></a>, <a href="https://www.163.com/dy/article/I0F7AM0M0511D05M.html"><b>Netease News</b></a> and <a href="https://www.sohu.com/a/657874198_121123740"><b>Sohu News</b></a> !
        </li>
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 2023: &nbsp; One paper is accepted by <a href="https://www.nature.com/articles/s41467-023-37136-1"><b>Nature Communications</b></a> !
        </li>
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 2023: &nbsp; One paper is accepted by <a href="https://openaccess.thecvf.com/content/CVPR2023/html/Yin_1_VS_100_Parameter-Efficient_Low_Rank_Adapter_for_Dense_Predictions_CVPR_2023_paper.html"><b>CVPR 2023 Main Track</b></a> !
        </li>
        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 2023: &nbsp; One paper is accepted by <a href="https://ieeexplore.ieee.org/abstract/document/10102360/"><b>IEEE Transactions on Intelligent Transportation Systems (TITS)</b></a>.
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 2023: &nbsp; One paper is accepted by <a href="https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Beyond_the_Limitation_of_Monocular_3D_Detector_via_Knowledge_Distillation_ICCV_2023_paper.html"><b>ICCV 2023 Main Track</b></a> !
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 2022: &nbsp; One paper is accepted by <a href="https://ieeexplore.ieee.org/abstract/document/9956875"><b>IEEE Transactions on Transactions on Multimedia (TMM)</b></a>.
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 2022: &nbsp; One paper is accepted by <a href="https://ieeexplore.ieee.org/abstract/document/9832637"><b>IEEE Transactions on Geoscience and Remote Sensing (TGRS)</b></a>.
        </li>

        <li data-aos="fade-up" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true" class="aos-init aos-animate">
          • 2022: &nbsp; One paper is accepted by <a href="https://ieeexplore.ieee.org/abstract/document/9884328"><b>IEEE IGARSS 2022</b></a>.
        </li>

      </ul>
    </div>
  </div>
</div>



<!--==========================================
                   Publications
===========================================-->
<div class="section publications-section scrollspy" id="publications">

  <div class="row container">
    <div class="row">
      <div class="title">📝 Publications</div>
      <hr>
    </div>
    <div class="row">
          <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <img class="responsive-img" src="./nc-fig.png">
          </div>

          <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <div class="paper-title">Revealing influencing factors on global waste distribution via deep-learning based dumpsite detection from satellite imagery</div>
            <div class="paper-author">Xian Sun*, <font color="#0000dd"><b>Dongshuo Yin*</b></font>, Fei Qin, Hongfeng Yu, Wanxuan Lu, Fanglong Yao, Qibin He, Xingliang Huang, Zhiyuan Yan, Peijin Wang, Chubo Deng, Nayu Liu, Yiran Yang, Wei Liang, Ruiping Wang, Cheng Wang, Naoto Yokoya, Ronny Hänsch, Kun Fu</div>
            <div class="paper-conf"><em><font color="#ff0000"><b>Nature Communications</b></font> <b>(Nat. Comm., IF=17.694, Co-first author with the supervisor)</b></em></div>
            <div>
                [<a href="https://www.nature.com/articles/s41467-023-37136-1">Paper Link</a>]
<!--                [<a href="https://github.com/DongshuoYin/garbage_dump_detection">Code</a>]-->
<!--                [<a href="https://www.scidb.cn/s/6bq2M3">Dataset</a>]-->
            </div>
          </div>
      </div>

      <hr class="publication-hr">
      <div class="row">
          <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <img class="responsive-img" src="./mona1.png">
          </div>

          <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <div class="paper-title">5% > 100%: BreakingPerformance Shackles of Full Fine-Tuning on Visual Recognition Tasks</div>
            <div class="paper-author"><font color="#0000dd"><b>Dongshuo Yin</b></font>, Leiyi Hu, Bin Li, Youqun Zhang, Xue Yang</div>
            <div class="paper-conf"><em> Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition <b>(IEEE CVPR 2025, CCF-A, Main Track)</b> </em></div>
            <div>
              [<a href="https://openaccess.thecvf.com/content/CVPR2025/papers/Yin_5100_Breaking_Performance_Shackles_of_Full_Fine-Tuning_on_Visual_Recognition_CVPR_2025_paper.pdf">Paper Link</a>]
            </div>
          </div>
      </div>

      <hr class="publication-hr">
      <div class="row">
          <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <img class="responsive-img" src="./e3va.png">
          </div>

          <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <div class="paper-title">Parameter-efficient is not sufficient: Exploring Parameter, Memory, and Time Efficient Adapter Tuning for Dense Predictions</div>
            <div class="paper-author"><font color="#0000dd"><b>Dongshuo Yin</b></font>, Xueting Han, Bin Li, Hao Feng, Jing Bai</div>
            <div class="paper-conf"><em> Proceedings of the ACM International Conference on Multimedia <b>(ACM MM 2024, CCF-A, Main Track)</b></em></div>
            <div>
              [<a href="https://dl.acm.org/doi/10.1145/3664647.3680940">Paper Link</a>]
            </div>
          </div>
      </div>


      <hr class="publication-hr">
      <div class="row">
          <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <img class="responsive-img" src="./cvpr23-fig.png">
          </div>

          <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <div class="paper-title">1% VS 100%: Parameter-Efficient Low Rank Adapter for Dense Predictions</div>
            <div class="paper-author"><font color="#0000dd"><b>Dongshuo Yin</b></font>, Yiran Yang, Zhechao Wang, Hongfeng Yu, Kaiwen Wei, Xian Sun</div>
            <div class="paper-conf"><em>Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition <b>(IEEE CVPR 2023, CCF-A, Main Track)</b></em></div>
            <div>
              [<a href="https://openaccess.thecvf.com/content/CVPR2023/html/Yin_1_VS_100_Parameter-Efficient_Low_Rank_Adapter_for_Dense_Predictions_CVPR_2023_paper.html">Paper Link</a>]
            </div>
          </div>
      </div>


      <hr class="publication-hr">
      <div class="row">
          <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <img class="responsive-img" src="./tits-fig.png">
          </div>

          <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <div class="paper-title">GAL: Graph-Induced Adaptive Learning for Weakly Supervised 3D Object Detection</div>
            <div class="paper-author"><font color="#0000dd"><b>Dongshuo Yin</b></font>, Hongfeng Yu, Nayu Liu, Fanglong Yao, Qibin He, Jihao Li, Yiran Yang, Shiyao Yan, Xian Sun</div>
            <div class="paper-conf"><em>IEEE Transactions on Intelligent Transportation Systems <b>(IEEE TITS, CCF-B, IF=9.6)</b></em></div>
            <div>
                [<a href="https://ieeexplore.ieee.org/abstract/document/10102360/">Paper Link</a>]
            </div>
          </div>
      </div>
      <hr class="publication-hr">
            <div class="row">
          <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <img class="responsive-img" src="./iccv-fig.png">
          </div>

          <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <div class="paper-title">Beyond the Limitation of Monocular 3D Detector via Knowledge Distillation</div>
            <div class="paper-author">Yiran Yang*, <font color="#0000dd"><b>Dongshuo Yin*</b></font>, Xuee Rong, Xian Sun, Wenhui Diao, Xinming Li</div>
            <div class="paper-conf"><em>Proceedings of the IEEE/CVF International Conference on Computer Vision <b>(IEEE ICCV 2023, CCF-A, Main Track)</b></em></div>
            <div>
              [<a href="https://openaccess.thecvf.com/content/ICCV2023/html/Yang_Beyond_the_Limitation_of_Monocular_3D_Detector_via_Knowledge_Distillation_ICCV_2023_paper.html">Paper Link</a>]
            </div>
          </div>
      </div>

      <hr class="publication-hr">
      <div class="row">
          <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <img class="responsive-img" src="./dape.png">
          </div>

          <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <div class="paper-title">DAPE: Dual-Stage Parameter-Efficient Fine-Tuning for Consistent Video Editing with Diffusion Models</div>
            <div class="paper-author">Junhao Xia, Chaoyang Zhang, Yecheng Zhang, Chengyang Zhou, Zhichang Wang, Bochun Liu, <font color="#0000dd"><b>Dongshuo Yin<sup>†</sup></b></font></div>
            <div class="paper-conf"><em> arXiv <b>( <sup>†</sup>corr. author, under review)</b> </em></div>
            <div>
              [<a href="https://arxiv.org/pdf/2505.07057">Paper Link</a>]
            </div>
          </div>
      </div>

    
    
      <hr class="publication-hr">
      <div class="row">
          <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <img class="responsive-img" src="./tea.png">
          </div>

          <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <div class="paper-title">TEA: A Training-Efficient Adapting Framework for Tuning Foundation Models in Remote Sensing</div>
            <div class="paper-author">Leiyi Hu, Wanxuan Lu, Hongfeng Yu, <font color="#0000dd"><b>Dongshuo Yin</b></font>, Xian Sun, Kun Fu</div>
            <div class="paper-conf"><em>IEEE Transactions on Geoscience and Remote Sensing <b>(IEEE TGRS, CCF-B, IF=7.5)</b></em></div>
            <div>
              [<a href="https://ieeexplore.ieee.org/document/10740309">Paper Link</a>]
            </div>
          </div>
      </div>



      




      <hr class="publication-hr">
      <div class="row">
          <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <img class="responsive-img" src="./airs.png">
          </div>

          <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <div class="paper-title">AiRs: Adapter in Remote Sensing for Parameter-Efficient Transfer Learning</div>
            <div class="paper-author">Leiyi Hu, Hongfeng Yu, Wanxuan Lu, <font color="#0000dd"><b>Dongshuo Yin</b></font>, Xian Sun, Kun Fu</div>
            <div class="paper-conf"><em>IEEE Transactions on Geoscience and Remote Sensing <b>(IEEE TGRS, CCF-B, IF=7.5)</b></em></div>
            <div>
              [<a href="https://ieeexplore.ieee.org/document/10385180">Paper Link</a>]
            </div>
          </div>
      </div>






      <hr class="publication-hr">
      <div class="row">
          <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <img class="responsive-img" src="./tmm.png">
          </div>

          <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <div class="paper-title">Optimal Partition Assignment for Universal Object Detection</div>
            <div class="paper-author"> Yiran Yang, Xian Sun, Wenhui Diao, Xuee Rong, Shiyao Yan, <font color="#0000dd"><b>Dongshuo Yin</b></font>, Xinming Li</div>
            <div class="paper-conf"><em>IEEE Transactions on MultiMedia <b>(IEEE TMM, CCF-B, IF=8.4)</b></em></div>
            <div>
              [<a href="https://ieeexplore.ieee.org/abstract/document/9956875/">Paper Link</a>]
            </div>
          </div>
      </div>

      <hr class="publication-hr">
      <div class="row">
          <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <img class="responsive-img" src="./tgrs2.png">
          </div>

          <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <div class="paper-title"> Statistical Sample Selection and Multivariate Knowledge Mining for Lightweight Detectors in Remote Sensing Imagery</div>
            <div class="paper-author"> Yiran Yang, Xian Sun, Wenhui Diao, <font color="#0000dd"><b>Dongshuo Yin</b></font>, Zhujun Yang, Xinming Li</div>
            <div class="paper-conf"><em>IEEE Transactions on Geoscience and Remote Sensing <b>(IEEE TGRS, CCF-B, IF=7.5)</b></em></div>
            <div>
              [<a href="https://ieeexplore.ieee.org/abstract/document/9832637">Paper Link</a>]
            </div>
          </div>
      </div>



</div>

<!-- ==========================================
                   Projects
=========================================== -->
<div id="projects">

  <div class="row container">
    <div class="row">
      <div class="title">🛠 Projects</div>
      <hr>
    </div>

<!--      <hr class="publication-hr">-->
      <div class="row">
          <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
                <video  width="330" controls autoplay muted> <source src="./project_video_garbage_dump.mp4" type="video/mp4">
          </div>

          <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <div class="paper-title">Global Garbage Dump Detection</div>
            <div class="paper-conf">Organization: Aerospace Information Research Institute, Chinese Academy of Sciences</div>
              [<a href="https://new.qq.com/rain/a/20230617A0131300.html">Website</a>]
          </div>
      </div>
<!--      <hr class="publication-hr">-->
</div>




<!-- ==========================================
                   Work experience
=========================================== -->
<div id="WorkExperience">

  <div class="row container">
    <div class="row">
      <div class="title">💼 Work Experience</div>
      <hr>
    </div>
    <div class="row">
          <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <img class="responsive-img" src="./msra-fig.png" width="366">
          </div>

          <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <div class="paper-title">Microsoft Research Asia</div>
            <div class="paper-author">Systems Research Group</div>
            <div class="paper-conf"><em><b>Internship</b>: 2023.3-2023.12</em></div>
<!--            <div>-->
<!--                [<a href="https://www.grss-ieee.org/technical-committees/image-analysis-and-data-fusion/?tab=data-fusion-contest">Website</a>]-->
<!--                [<a href="https://github.com/AICyberTeam/DFC2023-baseline">Baseline</a>]-->
<!--            </div>-->
          </div>
      </div>
      <hr class="publication-hr">
      <div class="row">
          <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./alibaba-fig.png" width="366">
          </div>

          <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <div class="paper-title">Alibaba Group</div>
            <div class="paper-author">Intime BG</div>
            <div class="paper-conf"><em><b>Internship</b>: 2023.1-2023.3</em></div>
          </div>
      </div>
<!--      <hr class="publication-hr">-->
</div>

<!--==========================================
                   Education
===========================================-->
<div id="education">
  <div class="row container">
    <div class="row">
      <div class="title">🎓 Education</div>
      <hr>
    </div>
    
    <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <a href="https://www.ucas.ac.cn/" target="_blank">
            <img src="./University_of_Chinese_Academy_of_Sciences-Logo.png" width="380" align="center" class="img-responsive edu-img">
          </a>
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <p></p>
          <p></p>
          <p></p>
          <div class="degree"></div>
          <div class="degree"><b>Ph.D.</b> in <a href="https://www.ucas.ac.cn/">University of Chinese Academy of Sciences</a>, Beijing, China</div>
          <div class="date">Sep. 2019 - June. 2024</div>
        </div>
    </div>

    <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <a href="https://www.tsinghua.edu.cn/" target="_blank">
            <img src="./thu.png" width="260" align="center" class="img-responsive edu-img">
          </a>
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <p></p>
          <p></p>
          <p></p>
          <div class="degree"></div>
          <div class="degree"><b>PostDoc</b> in <a href="https://www.cs.tsinghua.edu.cn/csen/">Department of Computer Sciences and Technology, Tsinghua University</a>, Beijing, China</div>
          <div class="date">Sep. 2024 - June. 2026</div>
        </div>
    </div>

<!--    <div class="row">-->
<!--        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">-->
<!--          <a href="https://www.whu.edu.cn/" target="_blank">-->
<!--            <img src="./whu.jpeg" style="width:110px;height:100px;" align="center" class="img-responsive edu-img">-->
<!--          </a>-->
<!--        </div>-->

<!--        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">-->
<!--          <p></p>-->
<!--          <p></p>-->
<!--          <p></p>-->
<!--          <div class="degree"><b>B.E.</b> degree from <a href="https://www.whu.edu.cn/">Wuhan University</a>, Wuhan, China</div>-->
<!--          <div class="date">Sep. 2015 - Jun.2019</div>-->
<!--        </div>-->
<!--    </div>-->
  </div>
</div>
      
<!--==========================================
              Reviewer Services
===========================================-->

<div id="reviewerServices">
  <div class="row container">
    <div class="row">
      <div class="title">👓 Reviewer Services</div>
      <hr>
      <ul>
        <li>  • IEEE Transactions on Multimedia (IEEE TMM).</li>
        <li>  • Scientific Reports (Nature Portfolio Journals).</li>
        <li>  • NeurIPS 2024.</li>
        <li>  • ICLR 2025.</li>
        <li>  • IEEE Transactions on Image Processing (IEEE TIP).</li>
        <li>  • CVPR 2025.</li>
        <li>  • ICCV 2025.</li>
        <li>  • NeurIPS 2025.</li>
        <li>  • ACMMM 2025.</li>
        <li>  • IEEE Transactions on Intelligent Transportation Systems (IEEE TITS).</li>
      </ul>
    </div>
  </div>
</div>


<!-- ==========================================
             Academic Activities
=========================================== -->
<!--<div id="academicactivities">-->
<!--  <div class="row container">-->
<!--    <div class="row">-->
<!--      <div class="title">🛠 Academic Activities</div>      -->
<!--      <hr>-->
<!--      <h7>Conference Reviewers</h7>-->
<!--      <ul>-->
<!--        <li>  • IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2023</li>-->
<!--        <li>  • IEEE/CVF International Conference on Computer Vision (ICCV), 2023</li>-->
<!--        <li>  • European Conference on Computer Vision (ECCV), 2022</li>-->
<!--      </ul>-->
<!--      <h7>Journal Reviewers</h7>-->
<!--      <ul>-->
<!--        <li>  • Pattern Recognition (PR)</li>-->
<!--        <li>  • ISPRS Journal</li>-->
<!--        <li>  • Information Sciences</li>-->
<!--        <li>  • ACM Transactions on Multimedia Computing Communications and Applications (ACM TOMM)</li>-->
<!--        <li>  • IEEE Transactions on Geoscience and Remote Sensing (IEEE TGRS) </li>-->
<!--        <li>  • IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing (IEEE JSTARS) </li>-->
<!--      </ul>-->
<!--    </div>-->
<!--  </div>-->
<!--</div>-->

  
<!-- ==========================================
                   Awards
=========================================== -->
<div id="awards">
  <div class="row container">
    <div class="row">
      <div class="title">🎖 Awards</div>      
      <hr>
      <ul>
        
        <li>  • 2025: China National Postdoctoral Program for Innovative Talents (2025年度博士后创新人才支持计划).</li>
        <li>  • 2024: Shuimu Tsinghua Scholar for Postdoc Researcher (清华大学水木学者).</li>
        <li>  • 2024: CAS President Scholarship (中国科学院院长奖).</li>
        <li>  • 2020: Merit Student Award.</li>
        <li>  • 2018: National Scholarship (0.3%).</li>
        <li>  • 2018: American Mathematical Contest In Modeling (MCM) Honorable Mention Award.</li>
        <li>  • 2017: First Prize of Anhui Competition Area in Contemporary Undergraduate Mathematical Contest in Modeling (CUMCM).</li>

      </ul>
    </div>
  </div>
</div>


<center>
        <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=900&t=tt&d=uhOdw7jm_QVpMd4bbp2rp0d4UXNZ131O2FTe18POhdA&co=2d78ad&cmo=ff0000&cmn=ff9f00&ct=ffffff'></script>
</center>

<p></p>
<center>
    Copyright © 2022 &nbsp; Dongshuo Yin. All Rights Reserved.
</center>
    
</body></html>
  
